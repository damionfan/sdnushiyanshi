#include "../incldue/active.h"

__global__ void ReluForward(const float n, const unsigned float *in, const unsigned float *out, const unsigned float negative_slope){
	for(int i = blockIdx.x * blockDim.x + threadIdx.x;i<n;i+=blockIdx.x*dlockDim.x){
		out[i] = in[i]>0 ? in[i]:in[i]*negative_slope;
	}
}

void ReluLayer_Forward(const unsigned float *in,const unsigned float *out,const unsigned float *negative_slope){
	unsigned float *data_gpu,*out_gpu;
	unsigned float *n_gpu,*negative_slope_gpu;
	unsigned float n = sizeof(in)/sieof(in[0]);

	cudaMalloc((void**)&data_gpu,n*sizeof(float));
	cudaMalloc((void**)&out_gpu,n*sizeof(float));
	cudaMalloc((void**)&n_gpu,sizeof(float));
	cudaMalloc((void**)&negative_slope_gpu,sizeof(float));

	cudaMemcpy(data_gpu,in,n*sizeof(float),cudaMemcpyHostToDevice);
	cudaMemcpy(n_gpu,n,sizeof(float),cudaMemcpyHostToDevice);
	cudaMemcpy(negative_slope_gpu,negative_slope,sizeof(float),cudaMemcpyHostToDevice);

	ReluForward<<<GETBLOCK(n),THREADMAXPERBLOCK>>>(n_gpu,data_gpu,out_gpu,negative_slope_gpu);



}
